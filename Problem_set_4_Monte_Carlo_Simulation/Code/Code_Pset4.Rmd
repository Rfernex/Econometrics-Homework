---
title: "Pset 4 - Empirical"
author: "Romain Fernex"
date: "2025-03-16"
output:
  pdf_document:
    number_sections: true
    latex_engine: xelatex
    toc: true
  word_document:
    toc: true
  html_document:
    toc: true
    df_print: paged
header-includes: 
  - \usepackage{titlesec}
  - \usepackage{float} 
  - \usepackage{amsmath}
  - \usepackage{fontspec}
  - \usepackage{fvextra}
  - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
options(repos = c(CRAN = "https://cran.rstudio.com/")) # necessary to load the stargazer package
knitr::opts_chunk$set(comment = "") # improves output visuals by removing ##

if (!require(haven)) install.packages("haven")
if (!require(dplyr)) install.packages("dplyr")
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(labelled)) install.packages("labelled")
if (!require(tidyr)) install.packages("tidyr")
if (!require(ggplot2)) install.packages("ggplot2")
if (!require(skimr)) install.packages("skimr")
if (!require(knitr)) install.packages("knitr")
if (!require(stargazer)) install.packages("stargazer")
if (!require(KableExtra)) install.packages("KableExtra")
if (!require(car)) install.packages("car")
if (!require(car)) install.packages("cowplot")
library(kableExtra)
library(haven)
library(tidyverse)
library(labelled)
library(tidyr)
library(ggplot2)
library(dplyr)
library(skimr)
library(knitr)
library(stargazer)
library(car)
library(cowplot)
```

# Question 1 

```{r, include= TRUE}
set.seed(123)
x1  <- runif(1000, min = 0, max = 1)
u <- rchisq(1000, df = 1) - 1
data <- data.frame(x1 = x1, u = u)

par(mfrow = c(1, 2))  

# histogram for x1
p1 <- ggplot(data, aes(x = x1)) +
  geom_histogram(binwidth = 0.05, fill = 'skyblue', color = 'black', alpha = 0.8) +
  geom_vline(aes(xintercept = mean(x1), color = 'Mean'), linetype = 'dashed', linewidth  = 1) +
  geom_vline(aes(xintercept = median(x1), color = 'Median'), linetype = 'dotted', linewidth = 1) +
  scale_color_manual(name = 'Legend :', values = c('Mean' = 'red', 'Median' = 'blue')) +
  labs(title = 'Histogram of x1', x = 'x1', y = 'Count') +
  theme_minimal() +
  theme(
    plot.title = element_text(face = 'bold', hjust = 0, size = 10),
    axis.title = element_text(size = 10),
    legend.position.inside = c(0.95, 0.95),
    legend.justification = c('right', 'top'),
    legend.background = element_rect(color = 'black', fill = 'white', linewidth = 0.3),
    legend.margin = margin(2, 2, 2, 2),
    legend.box.margin = margin(0, 0, 0, 0),
    legend.title = element_text(size = 8, face = 'bold', margin = margin(b = 0))
  )

# histogram for u
p2 <- ggplot(data, aes(x = u)) +
  geom_histogram(binwidth = 0.5, fill = 'salmon', color = 'black', alpha = 0.8) +
  geom_vline(aes(xintercept = mean(u), color = 'Mean'), linetype = 'dashed', linewidth = 1) +
  geom_vline(aes(xintercept = median(u), color = 'Median'), linetype = 'dotted', linewidth = 1) +
  scale_color_manual(name = 'Legend :', values = c('Mean' = 'red', 'Median' = 'blue')) +
  labs(title = 'Histogram of u', x = 'u', y = 'Count') +
  theme_minimal() +
  theme(
    plot.title = element_text(face = 'bold', hjust = 0, size = 10),
    axis.title = element_text(size = 10),
    legend.position.inside = c(0.95, 0.95),
    legend.justification = c('right', 'top'),
    legend.background = element_rect(color = 'black', fill = 'white', linewidth = 0.3),
    legend.margin = margin(2, 2, 2, 2),
    legend.box.margin = margin(0, 0, 0, 0),
    legend.title = element_text(size = 8, face = 'bold', margin = margin(b = 0))
  )

plot_grid(p1, p2, ncol = 2)
```

# Question 2

## 2.a)
```{r, include= TRUE}
chi_mean_std <- function(N) {
  u <- rchisq(N, df = 1) - 1
  mean_u <- mean(u)
  sd_u <- sd(u)
  return(c(mean_u, sd_u))
}

```

## 2.b)
```{r, include= TRUE}
results_df <- data.frame(sample_mean=numeric(),sample_sd=numeric())  |>  setNames(c("sample_mean", "sample_sd"))
for (i in 1:10000) {
  res <- chi_mean_std(5)
  results_df <- rbind(results_df, data.frame(sample_mean = res[1], sample_sd = res[2]) )
}
 knitr::kable(head(results_df), format = "latex",  
              col.names = c("Sample Mean", "Sample SD"),  
              caption = "First 6 Rows of Chi-Square Simulation Results (N=5)",  
              digits = 4,  
              booktabs = TRUE) %>%  
   kableExtra::kable_styling(latex_options = c("striped", "hold_position"),  
                            full_width = FALSE,  
                            position = "center") 
```


## 2.c)

```{r, include= TRUE}
par(mfrow = c(1, 1))

mean_sample_means <- mean(results_df$sample_mean)
median_sample_means <- median(results_df$sample_mean)

# plots the histogram
p3 <- ggplot(results_df, aes(x = sample_mean)) +
  geom_histogram(binwidth = 0.1, fill = 'lightblue', color = 'black', alpha = 0.8) +
  geom_vline(aes(xintercept = mean_sample_means, color = 'Mean'), linetype = 'dashed', linewidth = 1) +
  geom_vline(aes(xintercept = median_sample_means, color = 'Median'), linetype = 'dotted', linewidth = 1) +
  scale_color_manual(name = 'Legend', values = c('Mean' = 'red', 'Median' = 'blue')) +
  labs(title = 'Histogram of means of u', x = 'u', y = 'Count') +
  theme_minimal() +
  theme(
    plot.title = element_text(face = 'bold', hjust = 0, size = 10),
    axis.title = element_text(size = 10),
    legend.position.inside = c(0.95, 0.95),
    legend.justification = c('right', 'top'),
    legend.background = element_rect(color = 'black', fill = 'white', linewidth = 0.3),
    legend.margin = margin(2, 2, 2, 2),
    legend.box.margin = margin(0, 0, 0, 0),
    legend.title = element_text(size = 8, face = 'bold', margin = margin(b = 0))
  )

print(p3)
```

# Question 3 

```{r, include= TRUE}
sample_mean_stats <- data.frame(sample_size = integer(),   
                                mean_of_means = numeric(),   
                                sd_of_means = numeric())  

num_iterations <- 10000  

for (N in c(10, 100, 1000)) {  
  results_df <- data.frame(sample_mean = numeric(), sample_sd = numeric())  
  for (j in 1:num_iterations) {  
    res <- chi_mean_std(N)  
    results_df <- rbind(results_df,   
                        data.frame(sample_mean = res[1], sample_sd = res[2]))  
  }  
  sample_mean_stats <- rbind(sample_mean_stats,   
                             data.frame(sample_size = N,   
                                        mean_of_means = mean(results_df$sample_mean),   
                                        sd_of_means = sd(results_df$sample_mean)))  
}  

knitr::kable(sample_mean_stats, format = "latex",    
              col.names = c("Sample Size", "Mean of Means", "SD of Means"),    
              caption = "Sample Mean Statistics",    
              booktabs = TRUE) %>%    
   kableExtra::kable_styling(latex_options = c("striped", "hold_position"),    
                             full_width = FALSE,    
                             position = "center")  
 
```
We can see that, as the sample size increases, the mean and standard deviation of sample means goes towards 0. 


# Question 4 
```{r, include= TRUE}
modified_sd <- sample_mean_stats %>%  
  pull(sd_of_means) %>% 
  first() %>%
  {list(  
      m100 = . * (sqrt(10) / sqrt(100)),  
      m1000 = . * (sqrt(10) / sqrt(1000))  
    )  
  }  

cat("Transformed standard deviation (100) : ", modified_sd$m100)
cat("Transformed standard deviation (1000) : ", modified_sd$m1000)
```
We clearly see that the standard deviation goes closer to 0 as we increase the denominator (which makes sense).By applying these transformations we get the predicted standard error of the mean of u for sample sizes 100 or 1000 respectively. 

We notice that these predicted values are very close from those we computed in 3 for samples of size 100 and 10 000 respectively.

We solve for N using the following equation : $sd_n = sd_{10} * \sqrt{\frac{10}{N}}$ with $sd_{10} \approx 0.44$ and $sd_n = 0.001$.
\begin{itemize}
\item This gives us $N \approx 2.10^6$.
\end{itemize}

# Question 5 
```{r, include= TRUE}
num_iterations <- 10000       

par(mfrow = c(1, 3))     

for (N in c(10, 100, 1000)) {      
  results_df <- data.frame(sample_mean = numeric(), sample_sd = numeric())      
  for (j in 1:num_iterations) {      
    res <- chi_mean_std(N)      
    results_df <- rbind(results_df,       
                        data.frame(sample_mean = res[1], sample_sd = res[2]))      
  }    
  mean_of_means <- mean(results_df$sample_mean)      
  sd_of_means <- sd(results_df$sample_mean)      
  
  hist(results_df$sample_mean,      
       main = paste("N =", N),      
       xlab = "Sample Mean",       
       col = "skyblue",       
       breaks = 30,  
       freq = FALSE)   
  
  grid(nx = NULL, ny = NULL, col = "gray", lty = "dotted", lwd = 1)  
  x_range <- par("usr")[1:2]  
  
  # Overlay normal curve with the calculated mean and sd  
  curve(dnorm(x, mean = mean_of_means, sd = sd_of_means),     
        add = TRUE,     
        col = "red",     
        lwd = 2,  
        from = x_range[1],  
        to = x_range[2])  
}  
```

In accordance with the central limit theorem, we can see that the distribution 
of the sample mean converges to a normal distribution.

# Question 6 

## Definition of the Function (a,b,c,d)
```{r, include= TRUE}
reg_function <- function(N) {  
  x1 <- runif(N, min = 0, max = 1)  
  x2 <- rbinom(N, size = 1, prob = 0.3)  
  u  <- rchisq(N, df = 1) - 1  
  y  <- 1 + 2*x1 + 10*x2 + u  
  data_df <- data.frame(x1 = x1, x2 = x2, y = y)    
  model <- lm(y ~ x1 + x2, data = data_df)  
  return(list(model=model, data_df=data_df))  
}  

simulation <- function(N){
  results_df <- as.data.frame(matrix(numeric(0), ncol = 6))  
  colnames(results_df) <- c("Intercept_coef", "Intercept_se", "x1_coef", "x1_se", "x2_coef", "x2_se")  
  for (i in 1:10000) {  
    outcome <- reg_function(N)  
    model <- outcome$model  
    data_df <- outcome$data_df  
    coefs <- summary(model)$coefficients  
    # Check if x2 has no variation in data  
    if(var(data_df$x2) == 0) {  
      # We assign x2_coef = 0 and x2_se = 0 because x2 is essentially constant  
      x2_coef_val <- 0  
      x2_se_val <- 0  
    } else {  
      x2_coef_val <- coefs["x2", "Estimate"]  
      x2_se_val <- coefs["x2", "Std. Error"]  
    }  
    results_df <- rbind(results_df, data.frame(   
      Intercept_coef = coefs["(Intercept)", "Estimate"],    
      Intercept_se   = coefs["(Intercept)", "Std. Error"],    
      x1_coef        = coefs["x1", "Estimate"],    
      x1_se          = coefs["x1", "Std. Error"],    
      x2_coef        = x2_coef_val,    
      x2_se          = x2_se_val  
    )) 
    } 
  return(results_df)
}
```

## Simulations (N=10)
```{r, include= TRUE}
simulation_results_10 <-simulation(10)
skim(simulation_results_10)
```


# Question 7

## Histogram : Simulations (N=10)
```{r, include= TRUE}
par(mfrow = c(1, 3))  
cols <- c("Intercept_coef", "x1_coef", "x2_coef")  

for(cl in cols){  
  vec <- simulation_results_10[[cl]]  
  hist(vec,   
       main = paste("N =", 10),   
       xlab = cl,   
       col = "skyblue",   
       breaks = 30,   
       freq = FALSE)  
  mean_p <- mean(vec, na.rm = TRUE)  
  sd_p <- sd(vec, na.rm = TRUE)  
  x_range <- range(vec, na.rm = TRUE) + c(-0.1, 0.1) * sd_p 
   grid(nx = NULL, ny = NULL, col = "gray", lty = "dotted", lwd = 1)  
  curve(dnorm(x, mean = mean_p, sd = sd_p),   
        add = TRUE,   
        col = "red",   
        lwd = 2,  
        from = x_range[1],  
        to = x_range[2])  
}  
```

## Simulations (N=1000)
```{r, include= TRUE}
simulation_results_1000 <-simulation(1000)
skim(simulation_results_10)
```

## Histogram : Simulations (N=1000)
```{r, include= TRUE}
par(mfrow = c(1, 3))  
cols <- c("Intercept_coef", "x1_coef", "x2_coef")  

for(col in cols){  
  vec <- simulation_results_1000[[col]]  
  hist(vec,   
       main = paste("N =", 1000),   
       xlab = col,   
       col = "skyblue",   
       breaks = 30,   
       freq = FALSE)  
  mean_p <- mean(vec)  
  sd_p   <- sd(vec)  
  
  # Define x-range based on data (with a little margin)  
  x_range <- range(vec, na.rm = TRUE) + c(-1, 1)*sd_p*0.1 
  grid(nx = NULL, ny = NULL, col = "gray", lty = "dotted", lwd = 1)  
  curve(dnorm(x, mean = mean_p, sd = sd_p),   
        add = TRUE, col = "red", lwd = 2,   
        from = x_range[1], to = x_range[2])  
}  
```

The more we increase the sample size (N), the more the distribution of the sample mean tends towards a normal distribution which is conform to the central limit theorem. Thus the coefficients converge to the population value. 

The mean and standard deviation of the standard error of coefficients tend towards zero as the sample size (N) increases, thus we can safely assert that this estimator is consistent (its variance is asymptotically null). 

# Question 8 

## Definition of the Function (a,b,c,d)
```{r, include = TRUE}
simulation2 <- function(N){ 
  test_results <- data.frame(F_statistic = numeric(0))  
  for (i in 1:10000) {  
    result <- tryCatch({  
      outcome <- reg_function(N)  
      model <- outcome$model  
      data_df <- outcome$data_df  
      # Check for aliased coefficients  
      if(any(is.na(coef(model)))) {  
        next  
      }  
      joint_test <- linearHypothesis(model, c("(Intercept) = 1", "x1 = 2"))  
      f_stat <- joint_test$F[2]  
    }, error = function(e) {  
      NA  
    })  
    if(!is.na(result)) {  
      test_results <- rbind(test_results, data.frame(F_statistic = result))  
    }  
  }  
  return(test_results)  
}
```


## Simulations (N = 10)
```{r, include = TRUE}
F_stat_vec_10 <- simulation2(10)$F_statistic  

sd_p_10 <- sd(F_stat_vec_10, na.rm = TRUE)  
x_range <- range(F_stat_vec_10, na.rm = TRUE)  
x_range[1] <- max(0, x_range[1] - 0.1 * sd_p_10)  
x_range[2] <- x_range[2] + 0.1 * sd_p_10  

# Plot histogram  
 df10 <- data.frame(F_stat = F_stat_vec_10)  
   
 p10 <- ggplot(df10, aes(x = F_stat)) +  
   geom_histogram(aes(y = ..density..), bins = 60, fill = "skyblue", color = "black", alpha = 0.8) +  
   geom_vline(aes(xintercept = mean(F_stat), color = "Mean"), linetype = "dashed", linewidth = 1) +  
   geom_vline(aes(xintercept = median(F_stat), color = "Median"), linetype = "dotted", linewidth = 1) +  
   scale_color_manual(name = "Legend", values = c("Mean" = "red", "Median" = "blue")) +  
   labs(title = "F Statistic Distribution (N = 10)", x = "F Statistic", y = "Density") +  
   coord_cartesian(xlim = x_range) +  
   theme_minimal() +  
   theme(  
     plot.title = element_text(face = "bold", hjust = 0, size = 10),  
     axis.title = element_text(size = 10),  
     legend.position.inside = c(0.95, 0.95),  
     legend.justification = c("right", "top"),  
     legend.background = element_rect(color = "black", fill = "white", linewidth = 0.3),  
     legend.margin = margin(2, 2, 2, 2),  
     legend.box.margin = margin(0, 0, 0, 0),  
     legend.title = element_text(size = 8, face = "bold", margin = margin(b = 0))  
   )  
 print(p10) 
```

## Simulations (N = 1000)
```{r, include = TRUE}
 F_stat_vec_1000 <- simulation2(1000)$F_statistic    
  
 sd_p_1000 <- sd(F_stat_vec_1000, na.rm = TRUE)  
 x_range <- range(F_stat_vec_1000, na.rm = TRUE)  
 x_range[1] <- max(0, x_range[1] - 0.1 * sd_p_1000)  
 x_range[2] <- x_range[2] + 0.1 * sd_p_1000  
   
# Plot histogram  
 df1000 <- data.frame(F_stat = F_stat_vec_1000)  
   
 p1000 <- ggplot(df1000, aes(x = F_stat)) +  
   geom_histogram(aes(y = ..density..), bins = 60, fill = "skyblue", color = "black", alpha = 0.8) +  
   geom_vline(aes(xintercept = mean(F_stat), color = "Mean"), linetype = "dashed", linewidth = 1) +  
   geom_vline(aes(xintercept = median(F_stat), color = "Median"), linetype = "dotted", linewidth = 1) +  
   scale_color_manual(name = "Legend", values = c("Mean" = "red", "Median" = "blue")) +  
   labs(title = "F Statistic Distribution (N = 1000)", x = "F Statistic", y = "Density") +  
   coord_cartesian(xlim = x_range) +  
   theme_minimal() +  
   theme(  
     plot.title = element_text(face = "bold", hjust = 0, size = 10),  
     axis.title = element_text(size = 10),  
     legend.position.inside = c(0.95, 0.95),  
     legend.justification = c("right", "top"),  
     legend.background = element_rect(color = "black", fill = "white", linewidth = 0.3),  
     legend.margin = margin(2, 2, 2, 2),  
     legend.box.margin = margin(0, 0, 0, 0),  
     legend.title = element_text(size = 8, face = "bold", margin = margin(b = 0))  
   )  
 print(p1000)   
```

# Question 9 

## 9.a)
```{r, include = TRUE}
critval_95_n10 <- qf(0.95, df1 = 2, df2 = 7)
critval_99_n10 <- qf(0.99, df1 = 2, df2 = 7)
critval_95_n1000 <- qf(0.95, df1 = 2, df2 = 997)
critval_99_n1000 <- qf(0.99, df1 = 2, df2 = 997)
```

## 9.b)
```{r, include = TRUE}
nb_reject_95_n10 <- sum(F_stat_vec_10 > critval_95_n10)
nb_reject_99_n10 <- sum(F_stat_vec_10 > critval_99_n10)
nb_reject_95_n1000 <- sum(F_stat_vec_1000 > critval_95_n1000)
nb_reject_99_n1000 <- sum(F_stat_vec_1000 > critval_99_n1000)

pct_reject_95_n10 <- (nb_reject_95_n10 / length(F_stat_vec_10)) * 100
pct_reject_99_n10 <- (nb_reject_99_n10 / length(F_stat_vec_10)) * 100
pct_reject_95_n1000 <- (nb_reject_95_n1000 / length(F_stat_vec_1000)) * 100
pct_reject_99_n1000 <- (nb_reject_99_n1000 / length(F_stat_vec_1000)) * 100

results_df <- data.frame(
  Distribution = c("F(2,10)", "F(2,10)", "F(2,1000)", "F(2,1000)"),
  Significance_Level = c("95%", "99%", "95%", "99%"),
  Critical_Value = c(critval_95_n10, critval_99_n10, critval_95_n1000, critval_99_n1000),
  Rejections_Count = c(nb_reject_95_n10, nb_reject_99_n10, nb_reject_95_n1000, nb_reject_99_n1000),
  Rejections_Percentage = c(pct_reject_95_n10, pct_reject_99_n10, pct_reject_95_n1000, pct_reject_99_n1000)
)

results_df$Critical_Value <- round(results_df$Critical_Value, 4)  
results_df$Rejections_Percentage <- round(results_df$Rejections_Percentage, 2)
```

```{r, include = TRUE}
kable(results_df, format = "latex",   
      col.names = c("Distribution", "Significance Level",  
                    "Critical Value", "Rejections Count", "Rejections (%)"),  
      caption = "F-Test Rejection Results"  
) %>%  
  kable_styling(bootstrap_options = c("striped", "hold_position"),   
                full_width = FALSE,   
                position = "center",  
                latex_options = "hold_position")  
```


## 9.c)
If the distribution of the error terms had been normal, we would expect that at the 95% (99%) confidence level we would reject $H_0$ for 5%(1%) of the samples tested. 

We notice that, based on our simulation, the observed rejection rates were much higher when the sample size is 10 (around 11% of rejection at the 95% confidence level and around 5% for the 99% confidence level) 

When we look at samples of larger sizes (1000), however, we notice observed results are much closer to the expected proportions ! 
\begin{itemize}
\item This is a direct illustration of the central limit theorem : a larger sample size improves the approximation to normality. 
\end{itemize}
















